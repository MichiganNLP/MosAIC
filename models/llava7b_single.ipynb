{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, AutoTokenizer, CLIPModel\n",
    "import torch\n",
    "import os\n",
    "import re \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longju/anaconda3/envs/llava/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa2446011484f2298c8858c9e700984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", torch_dtype=torch.float16)\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_llava_wImage(text_prompt, image_source, device):\n",
    "    image = Image.open(image_source)\n",
    "    prompt = text_prompt\n",
    "    \n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    generate_ids = model.generate(**inputs, max_length=100000)\n",
    "\n",
    "    full_response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "\n",
    "\n",
    "    response_parts = full_response.split(\"ASSISTANT:\", 1)\n",
    "    response = response_parts[1].strip() if len(response_parts) > 1 else \"\"\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image features a Christmas tree with a Mickey Mouse and Minnie Mouse dressed as Santa Claus and Mrs. Claus, surrounded by presents. The scene is set in a festive atmosphere, likely at a theme park or a special event. This image represents the popular culture of the United States, particularly the holiday season, and the iconic characters of Mickey and Minnie Mouse.\n"
     ]
    }
   ],
   "source": [
    "### TEST example\n",
    "\n",
    "image_source = \"\"\n",
    "\n",
    "prompt_sum = (f\"<image>\\n\"\n",
    "              f\"USER: Generate a comprehensive summary based on the image, to describe the contents of the image and the culture related knowledge about this picture. Limit response to 3 sentences. \\nASSISTANT:\")\n",
    "\n",
    "res = generate_response_llava_wImage(prompt_sum, image_source, device)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ''\n",
    "\n",
    "# Load DataFrame\n",
    "file_path = ''\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Captions: 100%|██████████| 6464/6464 [4:46:46<00:00,  2.66s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions generated and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "def apply_captioning(row):\n",
    "    full_image_path = os.path.join(base_path, row['imageRelPath'])\n",
    "    prompt = (f\"<image>\\n\"\n",
    "              f\"USER: Generate a comprehensive summary based on the image, to describe the contents of the image and the culture related knowledge about this picture. Limit response to 3 sentences. \\nASSISTANT:\")\n",
    "    return generate_response_llava_wImage(prompt, full_image_path, device)\n",
    "\n",
    "df['llava7b_caption'] = [apply_captioning(row) for row in tqdm(df.to_dict('records'), desc=\"Generating Captions\")]\n",
    "\n",
    "output_file_path = ''\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Captions generated and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
